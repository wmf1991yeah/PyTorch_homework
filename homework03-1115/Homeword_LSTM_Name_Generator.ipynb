{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/e/e7/集智AI学园首页左上角logo_2017.8.17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 火炬上的深度学习（下）第三节：神经网络莫扎特"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课后作业：使用 LSTM 编写一个国际姓氏生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在火炬课程中，我们学习了使用 LSTM 来生成 MIDI 音乐。这节课我们使用类似的方法，再创建一个 LSTM 国际起名大师！\n",
    "\n",
    "完成后的模型能够像下面这样使用，指定一个国家名，模型即生成几个属于这个国家的姓氏。\n",
    "\n",
    "```\n",
    "> python generate.py Russian\n",
    "Rovakov    Uantov    Shavakov\n",
    "\n",
    "> python generate.py German\n",
    "Gerren    Ereng    Rosher\n",
    "\n",
    "> python generate.py Spanish\n",
    "Salla    Parer    Allan\n",
    "\n",
    "> python generate.py Chinese\n",
    "Chan    Hang    Iun\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 第一步当然是引入PyTorch及相关包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "这次的数据仍然是18个文本文件，每个文件以“国家名字”命名，文件中存储了大量这个国家的姓氏。\n",
    "\n",
    "在读取这些数据前，为了简化神经网络的输入参数规模，我们把各国各语言人名都转化成用26个英文字母来表示，下面就是转换的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "nbpresent": {
     "id": "6a9d80df-1d38-4c41-849c-95e38da98cc7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "# all_letters 即课支持打印的字符+标点符号\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "# Plus EOS marker\n",
    "n_letters = len(all_letters) + 1 \n",
    "EOS = n_letters - 1\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicode_to_ascii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 `\"O'Néàl\"` 被转化成了以普通ASCII字符表示的 `O'Neal`。\n",
    "\n",
    "在上面的代码中，还要注意这么几个变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_letters:  abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'-\n",
      "n_letters:  59\n",
      "EOS:  58\n"
     ]
    }
   ],
   "source": [
    "# 姓氏中所有的可视字符\n",
    "print('all_letters: ', all_letters)\n",
    "# 所有字符的长度 +1 EOS结束符\n",
    "print('n_letters: ', n_letters)\n",
    "# 结束符，没有实质内容\n",
    "print('EOS: ', EOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中 `all_letters` 包含了我们数据集中所有可能出现的字符，也就是“字符表”。\n",
    "`n_letters` 是字符表的长度，在本例中长度为59。`EOS` 的索引号为58，它在字符表中没有对应的字符，仅代表结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好处理数据的方法，下面就可以放心的读取数据了。\n",
    "\n",
    "我们建立一个列表 `all_categories` 用于存储所有的国家名字。\n",
    "\n",
    "建立一个字典 `category_lines`，以读取的国名作为字典的索引，国名下存储对应国别的名字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories:  18 ['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n",
      "\n",
      "# Russian names:  ['Ababko', 'Abaev', 'Abagyan', 'Abaidulin', 'Abaidullin', 'Abaimoff', 'Abaimov', 'Abakeliya', 'Abakovsky', 'Abakshin']\n"
     ]
    }
   ],
   "source": [
    "# 按行读取出文件中的名字，并返回包含所有名字的列表\n",
    "def read_lines(filename):\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "    return [unicode_to_ascii(line) for line in lines]\n",
    "\n",
    "\n",
    "# category_lines是一个字典\n",
    "# 其中索引是国家名字，内容是从文件读取出的这个国家的所有名字\n",
    "category_lines = {}\n",
    "# all_categories是一个列表\n",
    "# 其中包含了所有的国家名字\n",
    "all_categories = []\n",
    "# 循环所有文件\n",
    "for filename in glob.glob('./names/*.txt'):\n",
    "    # 从文件名中切割出国家名字\n",
    "    category = filename.split('\\\\')[-1].split('.')[0]\n",
    "    # 将国家名字添加到列表中\n",
    "    all_categories.append(category)\n",
    "    # 读取对应国别文件中所有的名字\n",
    "    lines = read_lines(filename)\n",
    "    # 将所有名字存储在字典中对应的国别下\n",
    "    category_lines[category] = lines\n",
    "\n",
    "# 共有的国别数\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print('# categories: ', n_categories, all_categories)\n",
    "print()\n",
    "print('# Russian names: ', category_lines['Russian'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20074\n"
     ]
    }
   ],
   "source": [
    "# 再统计下手头共有多少条训练数据\n",
    "all_line_num = 0\n",
    "for key in category_lines:\n",
    "    all_line_num += len(category_lines[key])\n",
    "print(all_line_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们的数据准备好了，可以搭建神经网络了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先建立一个可以随机选择数据对 `(category, line)` 的方法，以方便训练时调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('French', 'Bonnet')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_training_pair():\n",
    "    # 随机选择一个国别名\n",
    "    category = random.choice(all_categories)\n",
    "    # 读取这个国别名下的所有人名\n",
    "    line = random.choice(category_lines[category])\n",
    "    return category, line\n",
    "\n",
    "print(random_training_pair())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先处理国别，将国别名转化为索引。\n",
    "\n",
    "这个索引是要和姓氏一起传入神经网络模型的。我们这次编写的是根据“国名条件”生成“符合条件的姓氏”的 LSTM 模型。这种将“条件”和“符合条件的数据”合并一起作为训练输入数据的方法，在“条件模型”里非常流行。\n",
    "\n",
    "比如 条件GAN（Conditional GAN），在训练时是把数据标签拼接到数据图片中一起进行训练的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# 将名字所属的国家名转化为“独热向量”\n",
    "def make_category_input(category):\n",
    "    li = all_categories.index(category)\n",
    "    return  li\n",
    "\n",
    "print(make_category_input('Italian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "对于训练过程中的每一步，或者说对于训练数据中每个名字的每个字符来说，神经网络的输入是 `(category, current letter, hidden state)`，输出是 `(next letter, next hidden state)`。\n",
    "\n",
    "与在课程中讲的一样，神经网络还是依据“当前的字符”预测“下一个字符”。比如对于“Kasparov”这个名字，创建的（input, target）数据对是 (\"K\", \"a\"), (\"a\", \"s\"), (\"s\", \"p\"), (\"p\", \"a\"), (\"a\", \"r\"), (\"r\", \"o\"), (\"o\", \"v\"), (\"v\", \"EOS\")。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "cf311809-10bf-40f7-87e1-1952342f7f35"
    }
   },
   "outputs": [],
   "source": [
    "def make_chars_input(nameStr):\n",
    "    name_char_list = list(map(lambda x: all_letters.find(x), nameStr))\n",
    "    return name_char_list\n",
    "\n",
    "\n",
    "def make_target(nameStr):\n",
    "    target_char_list = list(map(lambda x: all_letters.find(x), nameStr[1:]))\n",
    "    target_char_list.append(n_letters - 1)# EOS\n",
    "    return target_char_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样为了训练时方便使用，我们建立一个 `random_training_set` 函数，以随机选择出数据集 `(category, line)` 并转化成训练需要的 Tensor： `(category, input, target) `。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    # 随机选择数据集\n",
    "    category, line = random_training_pair()\n",
    "    #print(category, line)\n",
    "    # 转化成对应 Tensor\n",
    "    category_input = make_category_input(category)\n",
    "    line_input = make_chars_input(line)\n",
    "    #category_name_input = make_category_name_input(category, line)\n",
    "    line_target = make_target(line)\n",
    "    return category_input, line_input, line_target\n",
    "    #return category_name_input, line_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, [31, 4, 17, 4, 3, 0, 24], [4, 17, 4, 3, 0, 24, 58])\n"
     ]
    }
   ],
   "source": [
    "print(random_training_set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4ff5f52a-2523-47f0-beba-f6c29d412e5f"
    }
   },
   "source": [
    "# 搭建神经网络\n",
    "\n",
    "这次使用的 LSTM 神经网络整体结构上与课上讲的生成音乐的模型非常相似，不过有一点请注意一下。\n",
    "\n",
    "我们要把国别和国别对应的姓氏一同输入到神经网络中，这样 LSTM 模型才能分别学习到每个国家姓氏的特色，从而生成不同国家不同特色的姓氏。\n",
    "\n",
    "那国别数据与姓氏数据应该如何拼接哪？应该在嵌入前拼接，还是在嵌入后再进行拼接哪？嵌入后的维度与 hidden_size 有怎样的关系哪？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要参考课上的模型，将这个模型补充完整。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 一个手动实现的LSTM模型，\n",
    "\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, category_size, name_size, hidden_size, output_size, num_layers = 1):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "       \n",
    "        # 进行嵌入\n",
    "        self.embedding1 = nn.Embedding(category_size, hidden_size)\n",
    "        self.embedding2 = nn.Embedding(name_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size * 2, hidden_size, num_layers, batch_first =True)\n",
    "        \n",
    "        # 隐含层内部的相互链接\n",
    "        self.fc =nn.Linear(hidden_size, output_size)\n",
    "        # 输出层\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "\n",
    "    def forward(self, category_variable, name_variable, hidden):\n",
    "        \n",
    "        # 先分别进行embedding层的计算\n",
    "        category = self.embedding1(category_variable)\n",
    "        name = self.embedding2(name_variable)\n",
    "        input_variable = torch.cat((category,name), 2)\n",
    "        \n",
    "        # 从输入到隐含层的计算\n",
    "        output, hidden = self.lstm(input_variable, hidden)\n",
    "        \n",
    "        # output的尺寸：batch_size, len_seq, hidden_size\n",
    "        output = output[:, -1, :]\n",
    "        \n",
    "\n",
    "        # 全连接层\n",
    "        output = self.fc(output)\n",
    "\n",
    "        # output的尺寸：batch_size, output_size\n",
    "        # softmax函数\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output, hidden\n",
    " \n",
    "    def initHidden(self):\n",
    "        # 对隐含单元的初始化\n",
    "        # 注意尺寸是： layer_size, batch_size, hidden_size\n",
    "        # 对隐单元的初始化\n",
    "        # 对引单元输出的初始化，全0.\n",
    "        # 注意hidden和cell的维度都是layers,batch_size,hidden_size\n",
    "        hidden = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        # 对隐单元内部的状态cell的初始化，全0\n",
    "        cell = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        return (hidden, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与之前处理得分类问题不同，在分类问题中只有最后的输出被使用。而在当前的 **生成** 姓氏的任务中，神经网络在每一步都会做预测，所以我们需要在每一步计算损失值。\n",
    "\n",
    "PyTorch 非常易用，它允许我们只是简单的把每一步计算的损失加起来，在遍历完一个姓氏后，再进行反向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要将训练函数补充完整，或者编写自己的训练函数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义训练函数，在这个函数里，我们可以随机选择一条训练数据，遍历每个字符进行训练\n",
    "def train_LSTM():\n",
    "    # 初始化 隐藏层、梯度清零、损失清零\n",
    "    hidden = lstm.initHidden()\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    \n",
    "    # 随机选取一条训练数据\n",
    "    category_input, line_input, line_target = random_training_set()\n",
    "    # 处理国别数据\n",
    "    category_variable = Variable(torch.LongTensor([category_input]).unsqueeze(0))\n",
    "    \n",
    "    # 循环字符\n",
    "    for t in range(len(line_input)):\n",
    "        # 姓氏\n",
    "        name_variable = Variable(torch.LongTensor([line_input[t]]).unsqueeze(0))\n",
    "        # 目标\n",
    "        name_target = Variable(torch.LongTensor([line_target[t]]))\n",
    "        # 传入模型\n",
    "        output, hidden = lstm(category_variable, name_variable, hidden)\n",
    "        # 累加损失\n",
    "        loss += criterion(output, name_target)\n",
    "    \n",
    "    # 计算平均损失\n",
    "    l = len(line_input)\n",
    "    loss = 1.0 * loss/1\n",
    "    # 反向传播、更新梯度\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们定义 `time_since` 函数，它可以打印出训练持续的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def time_since(t):\n",
    "    now = time.time()\n",
    "    s = now - t\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在下面你要定义损失函数、优化函数、实例化模型参数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 10\n",
    "num_epoch = 3\n",
    "learning_rate = 0.002\n",
    "# num_layers = 2\n",
    "\n",
    "# 实例化模型\n",
    "lstm = LSTMNetwork(n_categories, n_letters-1, HIDDEN_SIZE, n_letters)\n",
    "# 定义损失函数与优化方法\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练的过程与我们前几节课一样，都是老套路啦！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0轮，训练损失：17.44，训练进度：4.98%，（0m 33s）\n",
      "第0轮，训练损失：16.25，训练进度：9.96%，（1m 0s）\n",
      "第0轮，训练损失：15.68，训练进度：14.94%，（1m 25s）\n",
      "第0轮，训练损失：15.39，训练进度：19.93%，（1m 52s）\n",
      "第0轮，训练损失：15.15，训练进度：24.91%，（2m 18s）\n",
      "第0轮，训练损失：14.92，训练进度：29.89%，（2m 45s）\n",
      "第1轮，训练损失：13.75，训练进度：38.31%，（3m 30s）\n",
      "第1轮，训练损失：13.67，训练进度：43.3%，（3m 56s）\n",
      "第1轮，训练损失：13.60，训练进度：48.28%，（4m 22s）\n",
      "第1轮，训练损失：13.53，训练进度：53.26%，（4m 48s）\n",
      "第1轮，训练损失：13.51，训练进度：58.24%，（5m 14s）\n",
      "第1轮，训练损失：13.50，训练进度：63.22%，（5m 41s）\n",
      "第2轮，训练损失：13.37，训练进度：71.65%，（6m 26s）\n",
      "第2轮，训练损失：13.25，训练进度：76.63%，（6m 52s）\n",
      "第2轮，训练损失：13.29，训练进度：81.61%，（7m 20s）\n",
      "第2轮，训练损失：13.23，训练进度：86.59%，（7m 49s）\n",
      "第2轮，训练损失：13.23，训练进度：91.57%，（8m 15s）\n",
      "第2轮，训练损失：13.23，训练进度：96.56%，（8m 43s）\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "records = []\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epoch):\n",
    "    train_loss = 0\n",
    "    # 按所有数据的行数随机循环\n",
    "    for i in range(all_line_num):\n",
    "        i += 1\n",
    "        loss = train_LSTM()\n",
    "        train_loss += loss\n",
    "        \n",
    "        #每隔3000步，跑一次校验集，并打印结果\n",
    "        if i % 3000 == 0:\n",
    "            training_process = (all_line_num * epoch + i) / (all_line_num * num_epoch) * 100\n",
    "            training_process = '%.2f' % training_process\n",
    "            print('第{}轮，训练损失：{:.2f}，训练进度：{}%，（{}）'\\\n",
    "                .format(epoch, train_loss.data.numpy()[0] / i, float(training_process), time_since(start)))\n",
    "            records.append([train_loss.data.numpy()[0] / i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制观察损失曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们将训练过程中记录的损失绘制成一条曲线，观察下神经网络学习的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xd110d550>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd0bfa2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "a = [i[0] for i in records]\n",
    "plt.plot(a, label = 'Train Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为我在计算损失平均值时有“除0错误”，所以在损失曲线中有间断，大家可以改进我的计算方法，让损失曲线连贯起来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试使用神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然神经网络训练好了，那也就是说，我们喂给它第一个字符，他就能生成第二个字符，喂给它第二个字符，它就会生成第三个，这样一直持续下去，直至生成 EOS 才结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那下面我们编写 `generate_one` 函数以方便的使用神经网络生成我们想要的名字字符串，在这个函数里我们定义以下内容：\n",
    "\n",
    "* 建立输入国别，开始字符，初始隐藏层状态的 Tensor\n",
    "* 创建 `output_str` 变量，创建时其中只包含“开始字符”\n",
    "* 定义生成名字的长度最大不超过 `max_length`\n",
    "    * 将当前字符传入神经网络\n",
    "    * 在输出中选出预测的概率最大的下一个字符，同时取出当前的隐藏层状态\n",
    "    * 如果字符是 EOS，则生成结束\n",
    "    * 如果是常规字符，则加入到 `output_str` 中并继续下一个流程\n",
    "* 返回最终生成的名字字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要自行编写模型验证方法。 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "# 通过指定国别名 category\n",
    "# 以及开始字符 start_char\n",
    "# 还有混乱度 temperature 来生成一个名字\n",
    "def generate_one(category, start_char='A', temperature=0.2):\n",
    "    # 初始化输入数据，国别 以及 输入的第一个字符\n",
    "    # 国别\n",
    "    category_idx = make_category_input(random.choice(all_categories))\n",
    "    print(category_idx)\n",
    "    category_variable = Variable(torch.LongTensor([category_idx]).unsqueeze(0))\n",
    "    # 第一个字符\n",
    "    name_idx = make_chars_input(start_char)\n",
    "    name_variable =Variable(torch.LongTensor([name_idx]))\n",
    "    # 初始化隐藏层\n",
    "    hidden = lstm.initHidden()\n",
    "    \n",
    "\n",
    "    output_str = start_char\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        \n",
    "        # 调用模型\n",
    "        output, hidden = lstm(category_variable, name_variable, hidden)\n",
    "        \n",
    "        # 这里是将输出转化为一个多项式分布\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        # 从而可以根据混乱度 temperature 来选择下一个字符\n",
    "        # 混乱度低，则趋向于选择网络预测最大概率的那个字符\n",
    "        # 混乱度高，则趋向于随机选择字符\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # 生成字符是 EOS，则生成结束\n",
    "        if top_i == EOS:\n",
    "            break\n",
    "        else:\n",
    "            # 继续下一个字符\n",
    "            char = all_letters[top_i]\n",
    "            output_str += char\n",
    "            chars_input = make_chars_input(char)\n",
    "            name_variable = Variable(torch.LongTensor([chars_input]))\n",
    "            \n",
    "    return output_str\n",
    "\n",
    "# 再定义一个函数，方便每次生成多个名字\n",
    "def generate(category, start_chars='ABC'):\n",
    "    for start_char in start_chars:\n",
    "        print(generate_one(category, start_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Rontik\n",
      "16\n",
      "Uras\n",
      "10\n",
      "Shiso\n"
     ]
    }
   ],
   "source": [
    "generate('Russian', 'RUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Gari\n",
      "17\n",
      "Eng\n",
      "4\n",
      "Rars\n"
     ]
    }
   ],
   "source": [
    "generate('German', 'GER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Sokendi\n",
      "9\n",
      "Pari\n",
      "13\n",
      "Albashas\n"
     ]
    }
   ],
   "source": [
    "generate('Spanish', 'SPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Cherdis\n",
      "6\n",
      "Hars\n",
      "16\n",
      "Isha\n"
     ]
    }
   ],
   "source": [
    "generate('Chinese', 'CHI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 LSTM 预测的效果，但显然还不理想，我想你可以通过调整网络模型，或者通过调整超参数让模型表现的更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/c/ca/AI学园.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nbpresent": {
   "slides": {
    "10393c05-7962-4245-9228-8b7db4eb79a1": {
     "id": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "prev": "22628fc4-8309-4579-ba36-e5b01a841473",
     "regions": {
      "335fd672-4ee6-4b7c-a65f-3ecbf38305e1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cc294dae-dd8f-4288-8d3c-bb9fd3ad19bc",
        "part": "whole"
       },
       "id": "335fd672-4ee6-4b7c-a65f-3ecbf38305e1"
      }
     }
    },
    "22628fc4-8309-4579-ba36-e5b01a841473": {
     "id": "22628fc4-8309-4579-ba36-e5b01a841473",
     "prev": null,
     "regions": {
      "6cfa5157-02f6-48e3-8ce4-89641febbe59": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9a73330c-27c1-4957-8e95-c3b42bc14a71",
        "part": "whole"
       },
       "id": "6cfa5157-02f6-48e3-8ce4-89641febbe59"
      }
     }
    },
    "2f34f0df-3ccc-4416-9d5d-cb4b075f539f": {
     "id": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "prev": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "regions": {
      "e25707b9-630e-4ece-9f66-bfcbc8342d76": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "df50f546-6d02-4383-beab-90378f16576b",
        "part": "whole"
       },
       "id": "e25707b9-630e-4ece-9f66-bfcbc8342d76"
      }
     }
    },
    "3eb7f63f-04de-4f51-a240-38d5074bed6f": {
     "id": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "prev": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "regions": {
      "76282c28-a6ba-4a08-be6c-4f27f5b81ddf": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "53fb987f-4f42-4bf8-81ae-280ebdd19aee",
        "part": "whole"
       },
       "id": "76282c28-a6ba-4a08-be6c-4f27f5b81ddf"
      }
     }
    },
    "686bcaec-0623-4943-b227-f4e1c5975c4a": {
     "id": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "prev": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "regions": {
      "659c021e-7f79-4612-aa7d-8f1c48f91f8b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4ff5f52a-2523-47f0-beba-f6c29d412e5f",
        "part": "whole"
       },
       "id": "659c021e-7f79-4612-aa7d-8f1c48f91f8b"
      }
     }
    },
    "964ac1b6-c781-47e8-89f0-1f593d473cd0": {
     "id": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "prev": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "regions": {
      "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8ff6da45-57cd-46ca-b14a-3f560ce4d345",
        "part": "whole"
       },
       "id": "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5"
      }
     }
    },
    "cc4bd43a-59ec-4127-b1d8-ebd30162207a": {
     "id": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "prev": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "regions": {
      "1e6711af-7711-4579-ac7a-f893b0d86931": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cf311809-10bf-40f7-87e1-1952342f7f35",
        "part": "whole"
       },
       "id": "1e6711af-7711-4579-ac7a-f893b0d86931"
      }
     }
    },
    "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8": {
     "id": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "prev": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "regions": {
      "3b983e72-35fb-4d19-83b4-789a3394f61f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "597a765d-634b-41a8-a0c6-be5c019da150",
        "part": "whole"
       },
       "id": "3b983e72-35fb-4d19-83b4-789a3394f61f"
      }
     }
    },
    "e4c6fc30-f833-4368-99fe-5297b99f1f14": {
     "id": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "prev": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "regions": {
      "98a6b3b6-d2db-4d8a-bb16-a4307ede4803": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6a9d80df-1d38-4c41-849c-95e38da98cc7",
        "part": "whole"
       },
       "id": "98a6b3b6-d2db-4d8a-bb16-a4307ede4803"
      }
     }
    },
    "f1a487d8-4b0b-47df-988f-1161d66174b2": {
     "id": "f1a487d8-4b0b-47df-988f-1161d66174b2",
     "prev": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "regions": {
      "2c817a32-203d-404b-8bf5-ba17f7d27034": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "81fde336-785e-461b-a751-718a5f6bff88",
        "part": "whole"
       },
       "id": "2c817a32-203d-404b-8bf5-ba17f7d27034"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
